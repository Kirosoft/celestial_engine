{
  "llm": {
    "baseUrl": "http://localhost:11434",
    "apiKey": "***",
    "defaultModel": "gemma3:12b",
    "timeoutMs": 60000,
    "useStreaming": false,
    "provider": "ollama",
    "ollamaBaseUrl": "http://localhost:11434",
    "temperature": 0.7,
    "maxOutputTokens": 25000
  },
  "logging": {
    "level": "debug"
  },
  "features": {
    "enableExperimental": false
  }
}
